{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-28T09:43:37.952598600Z",
     "start_time": "2024-01-28T09:43:37.695430200Z"
    }
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# read local .env file\n",
    "# find_dotenv 函数通常用于搜索和定位目录树中的 .env 文件，而 load_dotenv 函数用于将 .env 文件中的变量加载到环境中。\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.3)\n",
    "# embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "也可以在同一链中使用多个内存类。要组合多个内存类，我们可以初始化CombinedMemory类，然后使用它。\n",
    "\"\"\"\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import (\n",
    "    CombinedMemory,\n",
    "    ConversationBufferMemory,\n",
    "    ConversationSummaryMemory,\n",
    ")\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "conv_memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history_lines\", input_key=\"input\"\n",
    ")\n",
    "\n",
    "summary_memory = ConversationSummaryMemory(llm=llm, input_key=\"input\")\n",
    "# Combined\n",
    "memory = CombinedMemory(memories=[conv_memory, summary_memory])\n",
    "_DEFAULT_TEMPLATE = \"\"\"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
    "\n",
    "Summary of conversation:\n",
    "{history}\n",
    "Current conversation:\n",
    "{chat_history_lines}\n",
    "Human: {input}\n",
    "AI:\"\"\"\n",
    "PROMPT = PromptTemplate(\n",
    "    input_variables=[\"history\", \"input\", \"chat_history_lines\"],\n",
    "    template=_DEFAULT_TEMPLATE,\n",
    ")\n",
    "conversation = ConversationChain(llm=llm, verbose=True, memory=memory, prompt=PROMPT)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T09:43:38.741753400Z",
     "start_time": "2024-01-28T09:43:38.043648500Z"
    }
   },
   "id": "48bc606b53505046"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\learn-langchain\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Summary of conversation:\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi!\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "'Hello! How can I assist you today?'"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.run(\"Hi!\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T09:43:42.646656600Z",
     "start_time": "2024-01-28T09:43:39.980950200Z"
    }
   },
   "id": "171fc7d2aa93e1b3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\" output\n",
    "D:\\anaconda3\\envs\\learn-langchain\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
    "  warn_deprecated(\n",
    "\n",
    "\n",
    "\n",
    "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
    "Prompt after formatting:\n",
    "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
    "\n",
    "Summary of conversation:\n",
    "\n",
    "Current conversation:\n",
    "\n",
    "Human: Hi!\n",
    "AI:\u001B[0m\n",
    "\n",
    "\u001B[1m> Finished chain.\u001B[0m\n",
    "\n",
    "'Hello! How can I assist you today?'\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9575defbbff2a64b"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Summary of conversation:\n",
      "The human greets the AI and the AI asks how it can assist.\n",
      "Current conversation:\n",
      "Human: Hi!\n",
      "AI: Hello! How can I assist you today?\n",
      "Human: Can you tell me a joke?\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "\"Sure! Here's a classic one for you: Why don't scientists trust atoms? Because they make up everything!\""
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.run(\"Can you tell me a joke?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T09:44:11.410998800Z",
     "start_time": "2024-01-28T09:43:46.364193500Z"
    }
   },
   "id": "350ed6b5c2f0e5e8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\" output\n",
    "\n",
    "\n",
    "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
    "Prompt after formatting:\n",
    "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
    "\n",
    "Summary of conversation:\n",
    "The human greets the AI and the AI asks how it can assist.\n",
    "Current conversation:\n",
    "Human: Hi!\n",
    "AI: Hello! How can I assist you today?\n",
    "Human: Can you tell me a joke?\n",
    "AI:\u001B[0m\n",
    "\n",
    "\u001B[1m> Finished chain.\u001B[0m\n",
    "\n",
    "\"Sure! Here's a classic one for you: Why don't scientists trust atoms? Because they make up everything!\"\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b935af21dc93e79"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
