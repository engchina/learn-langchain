{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-24T15:41:44.136588700Z",
     "start_time": "2023-12-24T15:41:43.785663100Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "sys.path.append('../..')\n",
    "\n",
    "# read local .env file\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "openai.api_base = os.environ['OPENAI_API_BASE']"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ChatPromptTemplate包装器"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3884b912020feafc"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='\\nYou are an expert data scientist\\nwith an expertise in building deep learning models.\\n'), HumanMessage(content='Explain the concept of NLP in a couple of lines')]\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    PromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "template = \"\"\"\n",
    "You are an expert data scientist\n",
    "with an expertise in building deep learning models.\n",
    "\"\"\"\n",
    "\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "human_template = \"Explain the concept of {concept} in a couple of lines\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "chat_prompt = chat_prompt.format_prompt(concept=\"NLP\")\n",
    "# print(chat_prompt.to_string())\n",
    "print(chat_prompt.to_messages())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T13:42:45.594240500Z",
     "start_time": "2023-12-24T13:42:45.357281500Z"
    }
   },
   "id": "c8304ccf93be3542"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## FewShotPromptTemplate包装器"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "682b863861963263"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\"input\": \"高\", \"output\": \"矮\"},\n",
    "    {\"input\": \"胖\", \"output\": \"瘦\"},\n",
    "    {\"input\": \"精力充沛\", \"output\": \"萎靡不振\"},\n",
    "    {\"input\": \"快乐\", \"output\": \"伤心\"},\n",
    "    {\"input\": \"黑\", \"output\": \"白\"},\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T13:42:46.397851400Z",
     "start_time": "2023-12-24T13:42:46.389815700Z"
    }
   },
   "id": "dd238486776368c2"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "example_prompt = PromptTemplate(input_variables=[\"input\", \"output\"],\n",
    "                                template=\"\"\"\n",
    "                                词语：{input} \\n\n",
    "                                反义词：{output} \\n\n",
    "                                \"\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T13:42:46.958546700Z",
     "start_time": "2023-12-24T13:42:46.950547300Z"
    }
   },
   "id": "28fd13e97e7f03e1"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\n                                词语：高 \\n\\n                                反义词：矮 \\n\\n                                '"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_prompt.format(**examples[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T13:42:49.007512Z",
     "start_time": "2023-12-24T13:42:48.990938600Z"
    }
   },
   "id": "39985eb40c2b661f"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "'来玩个反义词接龙游戏，我说词语，你说它的反义词\\n\\n\\n                                词语：高 \\n\\n                                反义词：矮 \\n\\n                                \\n\\n                                词语：胖 \\n\\n                                反义词：瘦 \\n\\n                                \\n\\n                                词语：精力充沛 \\n\\n                                反义词：萎靡不振 \\n\\n                                \\n\\n                                词语：快乐 \\n\\n                                反义词：伤心 \\n\\n                                \\n\\n                                词语：黑 \\n\\n                                反义词：白 \\n\\n                                \\n现在轮到你了，词语：好\\n反义词：'"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import FewShotPromptTemplate\n",
    "\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    example_separator=\"\\n\",\n",
    "    prefix=\"来玩个反义词接龙游戏，我说词语，你说它的反义词\\n\",\n",
    "    suffix=\"现在轮到你了，词语：{input}\\n反义词：\",\n",
    "    input_variables=[\"input\"],\n",
    ")\n",
    "few_shot_prompt.format(input=\"好\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T13:42:51.271474400Z",
     "start_time": "2023-12-24T13:42:51.261465900Z"
    }
   },
   "id": "6f0ec75f64f3290e"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "'冷\\n反义词：热'"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain = LLMChain(llm=ChatOpenAI(temperature=0), prompt=few_shot_prompt)\n",
    "chain.run(\"冷\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T13:42:55.719944500Z",
     "start_time": "2023-12-24T13:42:52.086741500Z"
    }
   },
   "id": "b065f72d9ee0bd95"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CommaSeparatedListOutputParser 输出解释器"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f7ed419ab3985f0"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T15:04:51.331595300Z",
     "start_time": "2023-12-24T15:04:51.314583400Z"
    }
   },
   "id": "9bab94dfb48183fd"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "output_parser = CommaSeparatedListOutputParser()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T15:04:51.720800300Z",
     "start_time": "2023-12-24T15:04:51.709878700Z"
    }
   },
   "id": "6c342222310448aa"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "format_instructions = output_parser.get_format_instructions()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T15:04:52.093657300Z",
     "start_time": "2023-12-24T15:04:52.077500400Z"
    }
   },
   "id": "90af9ea0ef323445"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"List five {subject}.\\n{format_instructions}\",\n",
    "    input_variables=[\"subject\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions},\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T15:04:52.455508400Z",
     "start_time": "2023-12-24T15:04:52.442802800Z"
    }
   },
   "id": "254bb790ec7c8345"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain = LLMChain(llm=ChatOpenAI(temperature=0, model_name=\"gpt-4\"), prompt=prompt)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T15:04:53.127668300Z",
     "start_time": "2023-12-24T15:04:52.864038800Z"
    }
   },
   "id": "d648e3aa855b2030"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "{'subject': 'ice cream flavors',\n 'text': 'Chocolate, Vanilla, Strawberry, Mint Chocolate Chip, Rocky Road'}"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = chain(\"ice cream flavors\")\n",
    "output"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T15:05:51.746257900Z",
     "start_time": "2023-12-24T15:05:47.964826700Z"
    }
   },
   "id": "e538b07ebab8cc41"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "['Chocolate', 'Vanilla', 'Strawberry', 'Mint Chocolate Chip', 'Rocky Road']"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_parser.parse(output['text'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T15:05:51.757202400Z",
     "start_time": "2023-12-24T15:05:51.743698700Z"
    }
   },
   "id": "5d0b844acf95059e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## PydanticOutputParser 输出器"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "be308a545eb815de"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from pydantic import BaseModel, Field, field_validator"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T15:43:41.507250900Z",
     "start_time": "2023-12-24T15:43:41.494519400Z"
    }
   },
   "id": "25e62aca28aa2d19"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "model = ChatOpenAI(temperature=0, streaming=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T15:43:42.347727900Z",
     "start_time": "2023-12-24T15:43:42.086914500Z"
    }
   },
   "id": "5da3135f5b93ecb1"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='Answer the user query.\\nThe output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"setup\": {\"description\": \"question to set up a joke\", \"title\": \"Setup\", \"type\": \"string\"}, \"punchline\": {\"description\": \"answer to resolve the joke\", \"title\": \"Punchline\", \"type\": \"string\"}}, \"required\": [\"setup\", \"punchline\"]}\\n```\\nTell me a joke.\\n')]\n",
      "content='{\\n  \"setup\": \"Why did the tomato turn red?\",\\n  \"punchline\": \"Because it saw the salad dressing!\"\\n}'\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'AIMessage' object has no attribute 'strip'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 27\u001B[0m\n\u001B[0;32m     25\u001B[0m output \u001B[38;5;241m=\u001B[39m model(_input\u001B[38;5;241m.\u001B[39mto_messages())\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28mprint\u001B[39m(output)\n\u001B[1;32m---> 27\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43moutput_parser\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparse\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[1;32mD:\\anaconda3\\envs\\learn-langchain\\lib\\site-packages\\langchain\\output_parsers\\pydantic.py:24\u001B[0m, in \u001B[0;36mPydanticOutputParser.parse\u001B[1;34m(self, text)\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mparse\u001B[39m(\u001B[38;5;28mself\u001B[39m, text: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m T:\n\u001B[0;32m     21\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     22\u001B[0m         \u001B[38;5;66;03m# Greedy search for 1st json candidate.\u001B[39;00m\n\u001B[0;32m     23\u001B[0m         match \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msearch(\n\u001B[1;32m---> 24\u001B[0m             \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124m.*\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124m}\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[43mtext\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstrip\u001B[49m(), re\u001B[38;5;241m.\u001B[39mMULTILINE \u001B[38;5;241m|\u001B[39m re\u001B[38;5;241m.\u001B[39mIGNORECASE \u001B[38;5;241m|\u001B[39m re\u001B[38;5;241m.\u001B[39mDOTALL\n\u001B[0;32m     25\u001B[0m         )\n\u001B[0;32m     26\u001B[0m         json_str \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     27\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m match:\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'AIMessage' object has no attribute 'strip'"
     ]
    }
   ],
   "source": [
    "# refer: https://docs.pydantic.dev/2.5/errors/usage_errors/#validator-instance-method\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
    "\n",
    "    @field_validator('setup')\n",
    "    @classmethod\n",
    "    def question_ends_with_question_mark(cls, field) -> str:\n",
    "        if field[-1] != \"?\":\n",
    "            raise ValueError(\"question must end with a question mark!\")\n",
    "        return field\n",
    "\n",
    "\n",
    "joke_query = \"Tell me a joke.\"\n",
    "output_parser = PydanticOutputParser(pydantic_object=Joke)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": output_parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "_input = prompt.format_prompt(query=joke_query)\n",
    "print(_input.to_messages())\n",
    "output = model(_input.to_messages())\n",
    "print(output)\n",
    "print(type(output))\n",
    "\n",
    "# AttributeError: 'AIMessage' object has no attribute 'strip'\n",
    "# print(output_parser.parse(output))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T15:46:44.854818Z",
     "start_time": "2023-12-24T15:46:39.667807600Z"
    }
   },
   "id": "4042de3a6422778a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4d3bdb4db814f5ab"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
