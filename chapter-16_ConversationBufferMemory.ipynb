{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# read local .env file\n",
    "# find_dotenv 函数通常用于搜索和定位目录树中的 .env 文件，而 load_dotenv 函数用于将 .env 文件中的变量加载到环境中。\n",
    "_ = load_dotenv(find_dotenv())\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T06:38:33.197178Z",
     "start_time": "2024-01-27T06:38:32.929544300Z"
    }
   },
   "id": "11853cef6228ec8f"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "BaseMemory 定义了一个长链存储内存的接口。\n",
    "它允许通过 load_memory_variable 方法读取存储的数据，并通过 save_context 方法存储新数据。\n",
    "ConversationBufferMemory，它只是 ChatMessageHistory 的一个包装器，用于提取变量中的消息。\n",
    "\"\"\"\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "memory = ConversationBufferMemory()\n",
    "memory.chat_memory.add_user_message(\"hi!\")\n",
    "memory.chat_memory.add_ai_message(\"whats up?\")\n",
    " "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T06:37:59.252921200Z",
     "start_time": "2024-01-27T06:37:58.561345Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "{'history': 'Human: hi!\\nAI: whats up?'}"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})\n",
    " "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T06:37:59.267663800Z",
     "start_time": "2024-01-27T06:37:59.253921300Z"
    }
   },
   "id": "e739c1113a86ca2c"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "\" output\\n{'history': 'Human: hi!\\nAI: whats up?'}\\n\""
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" output\n",
    "{'history': 'Human: hi!\\nAI: whats up?'}\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T06:38:01.156664700Z",
     "start_time": "2024-01-27T06:38:01.145664900Z"
    }
   },
   "id": "cc96b32cb7d7c62c"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "通过使用return_messages=True，我们还可以获取作为消息列表的历史记录\n",
    "\"\"\"\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "memory.chat_memory.add_user_message(\"hi!\")\n",
    "memory.chat_memory.add_ai_message(\"whats up?\")\n",
    " "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T06:38:08.583279500Z",
     "start_time": "2024-01-27T06:38:08.562258300Z"
    }
   },
   "id": "aae24cf1dddd8a4e"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "{'history': [HumanMessage(content='hi!'), AIMessage(content='whats up?')]}"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T06:38:12.328263400Z",
     "start_time": "2024-01-27T06:38:12.320432700Z"
    }
   },
   "id": "97505ca50723aba4"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "\" output\\n{'history': [HumanMessage(content='hi!'), AIMessage(content='whats up?')]}\\n\""
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" output\n",
    "{'history': [HumanMessage(content='hi!'), AIMessage(content='whats up?')]}\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T06:38:13.587262300Z",
     "start_time": "2024-01-27T06:38:13.569262800Z"
    }
   },
   "id": "8d410a43f1e2c837"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "让我们看看如何在链中使用它(设置 verose = True，这样我们就可以看到提示符)。\n",
    "\"\"\"\n",
    "from langchain.chains import ConversationChain\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    verbose=True, \n",
    "    memory=ConversationBufferMemory()\n",
    ")\n",
    " "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T06:38:39.581680700Z",
     "start_time": "2024-01-27T06:38:39.565381600Z"
    }
   },
   "id": "76b9a7db5d2f3fa"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi there!\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "'Hello! How can I assist you today?'"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi there!\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T06:38:41.462120800Z",
     "start_time": "2024-01-27T06:38:40.149165900Z"
    }
   },
   "id": "42c5e09bf187dd5e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\" output\n",
    "> Entering new ConversationChain chain...\n",
    "Prompt after formatting:\n",
    "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
    "\n",
    "Current conversation:\n",
    "\n",
    "Human: Hi there!\n",
    "AI:\n",
    "\n",
    "> Finished chain.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\" output\n",
    "'Hello! How can I assist you today?'\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d6cdde8474a6059d"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI: Hello! How can I assist you today?\n",
      "Human: Tell me about yourself.\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "'I am an AI created by OpenAI. I am designed to assist with various tasks and provide information on a wide range of topics. I have been trained on a large dataset of text from the internet, which allows me to generate responses based on the patterns and information I have learned. Is there anything specific you would like to know about me?'"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Tell me about yourself.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T06:42:55.023603100Z",
     "start_time": "2024-01-27T06:42:51.900271500Z"
    }
   },
   "id": "4415dfcebf870fe"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\" output\n",
    "> Entering new ConversationChain chain...\n",
    "Prompt after formatting:\n",
    "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
    "\n",
    "Current conversation:\n",
    "Human: Hi there!\n",
    "AI: Hello! How can I assist you today?\n",
    "Human: Tell me about yourself.\n",
    "AI:\n",
    "\n",
    "> Finished chain.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\" output\n",
    "'I am an AI created by OpenAI. I am designed to assist with various tasks and provide information on a wide range of topics. I have been trained on a large dataset of text from the internet, which allows me to generate responses based on the patterns and information I have learned. Is there anything specific you would like to know about me?'\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f63480bb837ec10"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
